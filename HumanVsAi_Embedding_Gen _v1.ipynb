{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dcd1c66-38c8-4763-ae67-2b62adc9da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44bdbe6a-693e-4f42-9eae-ed15c27baec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_fil.csv')\n",
    "test = pd.read_csv('test_fil.csv')\n",
    "val = pd.read_csv('val_fil.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fab4a3b-cd1d-4473-ad55-28701378ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57594</td>\n",
       "      <td>The food is always hot and made fresh. I prefe...</td>\n",
       "      <td>Flan-T5-XL</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343858</td>\n",
       "      <td>Seriously the slowest service you could ever h...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462221</td>\n",
       "      <td>This reaction is favored at low pressures but ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100762</td>\n",
       "      <td>Justin had owned his car for over five years, ...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639192</td>\n",
       "      <td>I got this. One I think you are mistaken it is...</td>\n",
       "      <td>OPT-2.7B</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text      source  \\\n",
       "0       57594  The food is always hot and made fresh. I prefe...  Flan-T5-XL   \n",
       "1      343858  Seriously the slowest service you could ever h...       Human   \n",
       "2      462221  This reaction is favored at low pressures but ...       Human   \n",
       "3      100762  Justin had owned his car for over five years, ...     GPT-3.5   \n",
       "4      639192  I got this. One I think you are mistaken it is...    OPT-2.7B   \n",
       "\n",
       "   prompt_id  text_length  word_count  \n",
       "0          0          169          34  \n",
       "1          0          331          63  \n",
       "2          0          610          98  \n",
       "3          0          550         109  \n",
       "4          0          193          36  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3d7b362-abe4-4958-a5ce-471d5ef78713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Model(\n",
       "  (wte): Embedding(50257, 768)\n",
       "  (wpe): Embedding(1024, 768)\n",
       "  (drop): Dropout(p=0.1, inplace=False)\n",
       "  (h): ModuleList(\n",
       "    (0-11): 12 x GPT2Block(\n",
       "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (attn): GPT2Attention(\n",
       "        (c_attn): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): GPT2MLP(\n",
       "        (c_fc): Conv1D()\n",
       "        (c_proj): Conv1D()\n",
       "        (act): NewGELUActivation()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2Model\n",
    "import torch\n",
    "\n",
    "# Assuming CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models with GPU support\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_model = GPT2Model.from_pretrained('gpt2').to(device)\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "bert_model.eval()\n",
    "gpt2_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e256988-ed98-43bd-98ea-801543360ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embeddings(text):\n",
    "    inputs = bert_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move input tensors to the GPU\n",
    "    with torch.no_grad():  # Temporarily set all the requires_grad flags to false\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()  # Move embeddings back to CPU\n",
    "\n",
    "def get_gpt2_embeddings(text):\n",
    "    inputs = gpt2_tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}  # Move input tensors to the GPU\n",
    "    with torch.no_grad():  # Temporarily set all the requires_grad flags to false\n",
    "        outputs = gpt2_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).detach().cpu().numpy()  # Move embeddings back to CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b2ce355-e0ed-4ed1-a666-65f39104306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0619e816-1304-4796-b912-160fdaf13dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57594</td>\n",
       "      <td>The food is always hot and made fresh. I prefe...</td>\n",
       "      <td>Flan-T5-XL</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>34</td>\n",
       "      <td>[[0.1458053, 0.018536663, 0.25950676, 0.172973...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343858</td>\n",
       "      <td>Seriously the slowest service you could ever h...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>63</td>\n",
       "      <td>[[0.20390975, 0.0711168, 0.18746778, 0.0818906...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462221</td>\n",
       "      <td>This reaction is favored at low pressures but ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>98</td>\n",
       "      <td>[[-0.46987852, 0.124872394, 0.20436251, -0.054...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text      source  \\\n",
       "0       57594  The food is always hot and made fresh. I prefe...  Flan-T5-XL   \n",
       "1      343858  Seriously the slowest service you could ever h...       Human   \n",
       "2      462221  This reaction is favored at low pressures but ...       Human   \n",
       "\n",
       "   prompt_id  text_length  word_count  \\\n",
       "0          0          169          34   \n",
       "1          0          331          63   \n",
       "2          0          610          98   \n",
       "\n",
       "                                     bert_embeddings  \n",
       "0  [[0.1458053, 0.018536663, 0.25950676, 0.172973...  \n",
       "1  [[0.20390975, 0.0711168, 0.18746778, 0.0818906...  \n",
       "2  [[-0.46987852, 0.124872394, 0.20436251, -0.054...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f182b5fd-45a7-43a4-96f2-7dfc6036cb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating GPT-2 Embeddings: 100%|██████████████████████████████████████████████████████████████████████| 253255/253255 [32:50<00:00, 128.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "#df = train.copy()\n",
    "# Apply the functions to the DataFrame\n",
    "#df['bert_embeddings'] = [get_bert_embeddings(text) for text in tqdm(df['text'], desc=\"Generating BERT Embeddings\")]\n",
    "df['gpt2_embeddings'] = [get_gpt2_embeddings(text) for text in tqdm(df['text'], desc=\"Generating GPT-2 Embeddings\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c60cfc-b121-4c15-9b14-9a91367aa43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating BERT Embeddings: 100%|█████████████████████████████████████████████████████████████████████████| 79143/79143 [10:34<00:00, 124.75it/s]\n",
      "Generating GPT-2 Embeddings: 100%|████████████████████████████████████████████████████████████████████████| 79143/79143 [10:14<00:00, 128.77it/s]\n"
     ]
    }
   ],
   "source": [
    "df_1 = test.copy()\n",
    "# Apply the functions to the DataFrame\n",
    "df_1['bert_embeddings'] = [get_bert_embeddings(text) for text in tqdm(df_1['text'], desc=\"Generating BERT Embeddings\")]\n",
    "df_1['gpt2_embeddings'] = [get_gpt2_embeddings(text) for text in tqdm(df_1['text'], desc=\"Generating GPT-2 Embeddings\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b53fc5c7-01fc-4cd8-9713-9b1b007a854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating BERT Embeddings: 100%|█████████████████████████████████████████████████████████████████████████| 63314/63314 [08:30<00:00, 123.98it/s]\n",
      "Generating GPT-2 Embeddings: 100%|████████████████████████████████████████████████████████████████████████| 63314/63314 [08:12<00:00, 128.55it/s]\n"
     ]
    }
   ],
   "source": [
    "df_2 = val.copy()\n",
    "# Apply the functions to the DataFrame\n",
    "df_2['bert_embeddings'] = [get_bert_embeddings(text) for text in tqdm(df_2['text'], desc=\"Generating BERT Embeddings\")]\n",
    "df_2['gpt2_embeddings'] = [get_gpt2_embeddings(text) for text in tqdm(df_2['text'], desc=\"Generating GPT-2 Embeddings\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec6c2aa-62ac-4390-9ceb-6ae2594457c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3155400/172881826.py:3: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['text', 'source', 'bert_embeddings', 'gpt2_embeddings'], dtype='object')]\n",
      "\n",
      "  df.to_hdf(f'{name}.h5', key='data', mode='w')\n"
     ]
    }
   ],
   "source": [
    "def save_as_hdf5(df, name):\n",
    "    # Save the entire DataFrame as an HDF5 file\n",
    "    df.to_hdf(f'{name}.h5', key='data', mode='w')\n",
    "\n",
    "save_as_hdf5(df, 'train_embeddings')\n",
    "save_as_hdf5(df_1, 'test_embeddings')\n",
    "save_as_hdf5(df_2, 'val_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46bf8f95-76c6-4972-86f8-68918aef4be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/MultiScaleDeformableAttention-1.0-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting tables\n",
      "  Downloading tables-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages (from tables) (1.26.3)\n",
      "Collecting numexpr>=2.6.2 (from tables)\n",
      "  Downloading numexpr-2.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: packaging in /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages (from tables) (23.2)\n",
      "Collecting py-cpuinfo (from tables)\n",
      "  Downloading py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting blosc2>=2.3.0 (from tables)\n",
      "  Downloading blosc2-2.6.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting ndindex>=1.4 (from blosc2>=2.3.0->tables)\n",
      "  Downloading ndindex-1.8-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting msgpack (from blosc2>=2.3.0->tables)\n",
      "  Downloading msgpack-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Downloading tables-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading blosc2-2.6.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numexpr-2.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (380 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.0/381.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Downloading ndindex-1.8-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m517.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m338.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading msgpack-1.0.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.3/408.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py-cpuinfo, numexpr, ndindex, msgpack, blosc2, tables\n",
      "Successfully installed blosc2-2.6.2 msgpack-1.0.8 ndindex-1.8 numexpr-2.10.0 py-cpuinfo-9.0.0 tables-3.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb5c14-850e-432a-9a4d-3441463124b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
