{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchgpipe import GPipe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "INPUT_DIM = 768\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 33\n",
    "NUM_LAYERS = 2\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 50\n",
    "DROPOUT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(INPUT_DIM, HIDDEN_DIM, NUM_LAYERS, dropout=DROPOUT, batch_first=True)\n",
    "        self.fc = nn.Linear(HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output, _ = self.lstm(x)\n",
    "        return self.fc(output[:, -1, :])  # Use last timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = np.array(embeddings)\n",
    "        self.labels = np.array(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.embeddings[idx], dtype=torch.float32), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and encode labels\n",
    "def load_data():\n",
    "    train_data = pd.read_hdf('train_embeddings.h5')\n",
    "    test_data = pd.read_hdf('test_embeddings.h5')\n",
    "    val_data = pd.read_hdf('val_embeddings.h5')\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    train_data['source'] = label_encoder.fit_transform(train_data['source'])\n",
    "    test_data['source'] = label_encoder.transform(test_data['source'])\n",
    "    val_data['source'] = label_encoder.transform(val_data['source'])\n",
    "\n",
    "    train_dataset = EmbeddingDataset(np.array(train_data['gpt2_embeddings']), np.array(train_data['source']))\n",
    "    test_dataset = EmbeddingDataset(np.array(test_data['gpt2_embeddings']), np.array(test_data['source']))\n",
    "    val_dataset = EmbeddingDataset(np.array(val_data['gpt2_embeddings']), np.array(val_data['source']))\n",
    "\n",
    "    return DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True), \\\n",
    "           DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False), \\\n",
    "           DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_loader, test_loader, val_loader = load_data()\n",
    "\n",
    "# Initialize model and wrap with GPipe\n",
    "model = LSTMModel()\n",
    "devices = ['cuda:0', 'cuda:1']  # Define the devices\n",
    "model = GPipe(model, balance=[1, 1], chunks=8, devices=devices)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train and evaluate\n",
    "def train_and_evaluate():\n",
    "    metric_records = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        start_time = time.time()\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(devices[0])  # Move data to the first device\n",
    "            labels = labels.to(devices[1])  # Labels to the last device in pipeline\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        elapsed_time = time.time() - start_time\n",
    "        gpu_memory = torch.cuda.memory_allocated('cuda:0') / (1024 ** 3)  # GPU memory in GB\n",
    "        system_memory = psutil.virtual_memory().used / (1024 ** 3)  # System memory in GB\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for data, labels in val_loader:\n",
    "                data = data.to(devices[0])\n",
    "                labels = labels.to(devices[1])\n",
    "                outputs = model(data)\n",
    "                val_preds.extend(outputs.argmax(dim=1).tolist())\n",
    "                val_labels.extend(labels.tolist())\n",
    "\n",
    "        acc = accuracy_score(val_labels, val_preds)\n",
    "        prec = precision_score(val_labels, val_preds, average='macro')\n",
    "        rec = recall_score(val_labels, val_preds, average='macro')\n",
    "        f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "\n",
    "        metric_records.append((epoch, total_loss, acc, prec, rec, f1, gpu_memory, system_memory, elapsed_time))\n",
    "        print(f'Epoch {epoch+1}: Loss={total_loss:.4f}, Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}')\n",
    "        print(f'GPU Memory: {gpu_memory} GB, System Memory: {system_memory} GB, Elapsed Time: {elapsed_time} sec')\n",
    "\n",
    "    return metric_records\n",
    "\n",
    "metrics = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting function \n",
    "def plot_metrics(metrics):\n",
    "    epochs, losses, accuracies, precisions, recalls, f1_scores, gpu_usages, memory_usages, times = zip(*metrics)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(epochs, losses, label='Loss')\n",
    "    plt.plot(epochs, accuracies, label='Accuracy')\n",
    "    plt.plot(epochs, precisions, label='Precision')\n",
    "    plt.plot(epochs, recalls, label='Recall')\n",
    "    plt.plot(epochs, f1_scores, label='F1 Score')\n",
    "    plt.title('Training Metrics')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(epochs, gpu_usages, label='GPU Usage (GB)')\n",
    "    plt.title('GPU Usage')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(epochs, times, label='Training Time (s)')\n",
    "    plt.title('Training Time per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(metrics)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
