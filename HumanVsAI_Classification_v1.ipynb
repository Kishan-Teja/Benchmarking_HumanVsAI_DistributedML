{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8b0586-ebf3-48e3-b398-a4dc3ef164eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9347e27-1980-4b8c-a4ee-ede44fb3adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_hdf('train_embeddings.h5')\n",
    "test = pd.read_hdf('test_embeddings.h5')\n",
    "val = pd.read_hdf('val_embeddings.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c533525-0a67-4b6d-aec5-5bd81c030359",
   "metadata": {},
   "source": [
    "## Data Prep for Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7312be17-c778-41d6-a484-fe12a2a9bbed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>bert_embeddings</th>\n",
       "      <th>gpt2_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57594</td>\n",
       "      <td>The food is always hot and made fresh. I prefe...</td>\n",
       "      <td>Flan-T5-XL</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>34</td>\n",
       "      <td>[[0.1458053, 0.018536663, 0.25950676, 0.172973...</td>\n",
       "      <td>[[0.07363588, 0.18456551, -0.7668689, -0.40527...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>343858</td>\n",
       "      <td>Seriously the slowest service you could ever h...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>331</td>\n",
       "      <td>63</td>\n",
       "      <td>[[0.20390975, 0.0711168, 0.18746778, 0.0818906...</td>\n",
       "      <td>[[-0.017117647, 0.13311762, -0.49339196, -0.29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>462221</td>\n",
       "      <td>This reaction is favored at low pressures but ...</td>\n",
       "      <td>Human</td>\n",
       "      <td>0</td>\n",
       "      <td>610</td>\n",
       "      <td>98</td>\n",
       "      <td>[[-0.46987852, 0.124872394, 0.20436251, -0.054...</td>\n",
       "      <td>[[-0.2966847, -0.14409573, -0.4495244, -0.1983...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100762</td>\n",
       "      <td>Justin had owned his car for over five years, ...</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>109</td>\n",
       "      <td>[[-0.087581664, 0.021991476, 0.24508698, 0.040...</td>\n",
       "      <td>[[0.23361564, -0.12555604, -0.33635634, -0.224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>639192</td>\n",
       "      <td>I got this. One I think you are mistaken it is...</td>\n",
       "      <td>OPT-2.7B</td>\n",
       "      <td>0</td>\n",
       "      <td>193</td>\n",
       "      <td>36</td>\n",
       "      <td>[[0.10058918, 0.0625017, 0.18879642, 0.1949409...</td>\n",
       "      <td>[[-0.03273765, 0.09610998, -0.46160632, -0.116...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text      source  \\\n",
       "0       57594  The food is always hot and made fresh. I prefe...  Flan-T5-XL   \n",
       "1      343858  Seriously the slowest service you could ever h...       Human   \n",
       "2      462221  This reaction is favored at low pressures but ...       Human   \n",
       "3      100762  Justin had owned his car for over five years, ...     GPT-3.5   \n",
       "4      639192  I got this. One I think you are mistaken it is...    OPT-2.7B   \n",
       "\n",
       "   prompt_id  text_length  word_count  \\\n",
       "0          0          169          34   \n",
       "1          0          331          63   \n",
       "2          0          610          98   \n",
       "3          0          550         109   \n",
       "4          0          193          36   \n",
       "\n",
       "                                     bert_embeddings  \\\n",
       "0  [[0.1458053, 0.018536663, 0.25950676, 0.172973...   \n",
       "1  [[0.20390975, 0.0711168, 0.18746778, 0.0818906...   \n",
       "2  [[-0.46987852, 0.124872394, 0.20436251, -0.054...   \n",
       "3  [[-0.087581664, 0.021991476, 0.24508698, 0.040...   \n",
       "4  [[0.10058918, 0.0625017, 0.18879642, 0.1949409...   \n",
       "\n",
       "                                     gpt2_embeddings  \n",
       "0  [[0.07363588, 0.18456551, -0.7668689, -0.40527...  \n",
       "1  [[-0.017117647, 0.13311762, -0.49339196, -0.29...  \n",
       "2  [[-0.2966847, -0.14409573, -0.4495244, -0.1983...  \n",
       "3  [[0.23361564, -0.12555604, -0.33635634, -0.224...  \n",
       "4  [[-0.03273765, 0.09610998, -0.46160632, -0.116...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "078c5a89-27a9-486e-a5a6-b09e716fec65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'source', 'prompt_id', 'text_length',\n",
       "       'word_count', 'bert_embeddings', 'gpt2_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2851a30c-a00a-492c-b36c-50a4be529d93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ba8120e-9bc4-4f54-99f7-b0284a5df064",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def data_prep(df):\n",
    "    # Assuming bert_embeddings are already in a compatible format\n",
    "    bert_embeddings_array = np.array([np.ravel(embedding) for embedding in df['bert_embeddings'].tolist()])\n",
    "\n",
    "    # Additional features with scaling\n",
    "    scaler = StandardScaler()\n",
    "    additional_features = scaler.fit_transform(df[['text_length', 'word_count']].values)\n",
    "\n",
    "    # Combine into a single feature array\n",
    "    X = np.column_stack((bert_embeddings_array, additional_features))\n",
    "    \n",
    "    # Labels (consider encoding if they are categorical/non-numeric)\n",
    "    y = df['source'].values\n",
    "    return X, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fed7c02-868c-4fc0-83ba-ef05e9f73468",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_prep(train)\n",
    "X_val, y_val = data_prep(val)\n",
    "X_test, y_test = data_prep(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ebfc81-05ff-4206-9db5-fba7a9f34f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/MultiScaleDeformableAttention-1.0-py3.12-linux-x86_64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages (from xgboost) (1.26.3)\n",
      "Requirement already satisfied: scipy in /home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages (from xgboost) (1.12.0)\n",
      "Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc5165a8-8430-4c30-9f6a-d906e3bd662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DMatrix with training data\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels to numeric categories\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "# Optionally, transform y_val and other label sets if necessary\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d09dd5b-0c4e-4543-923b-a2c403674d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [23:00:42] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [23:00:43] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"num_round\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:3.06740\teval-mlogloss:3.08083\n",
      "[1]\ttrain-mlogloss:2.87145\teval-mlogloss:2.89406\n",
      "[2]\ttrain-mlogloss:2.72593\teval-mlogloss:2.75680\n",
      "[3]\ttrain-mlogloss:2.60797\teval-mlogloss:2.64629\n",
      "[4]\ttrain-mlogloss:2.51206\teval-mlogloss:2.55709\n",
      "[5]\ttrain-mlogloss:2.42938\teval-mlogloss:2.48107\n",
      "[6]\ttrain-mlogloss:2.35779\teval-mlogloss:2.41603\n",
      "[7]\ttrain-mlogloss:2.29354\teval-mlogloss:2.35758\n",
      "[8]\ttrain-mlogloss:2.23553\teval-mlogloss:2.30561\n",
      "[9]\ttrain-mlogloss:2.18326\teval-mlogloss:2.25893\n",
      "[10]\ttrain-mlogloss:2.13571\teval-mlogloss:2.21695\n",
      "[11]\ttrain-mlogloss:2.09207\teval-mlogloss:2.17846\n",
      "[12]\ttrain-mlogloss:2.05235\teval-mlogloss:2.14444\n",
      "[13]\ttrain-mlogloss:2.01520\teval-mlogloss:2.11251\n",
      "[14]\ttrain-mlogloss:1.98110\teval-mlogloss:2.08338\n",
      "[15]\ttrain-mlogloss:1.94874\teval-mlogloss:2.05581\n",
      "[16]\ttrain-mlogloss:1.91904\teval-mlogloss:2.03099\n",
      "[17]\ttrain-mlogloss:1.89089\teval-mlogloss:2.00765\n",
      "[18]\ttrain-mlogloss:1.86453\teval-mlogloss:1.98618\n",
      "[19]\ttrain-mlogloss:1.83953\teval-mlogloss:1.96597\n",
      "[20]\ttrain-mlogloss:1.81595\teval-mlogloss:1.94716\n",
      "[21]\ttrain-mlogloss:1.79331\teval-mlogloss:1.92929\n",
      "[22]\ttrain-mlogloss:1.77193\teval-mlogloss:1.91256\n",
      "[23]\ttrain-mlogloss:1.75191\teval-mlogloss:1.89697\n",
      "[24]\ttrain-mlogloss:1.73253\teval-mlogloss:1.88196\n",
      "[25]\ttrain-mlogloss:1.71398\teval-mlogloss:1.86792\n",
      "[26]\ttrain-mlogloss:1.69666\teval-mlogloss:1.85486\n",
      "[27]\ttrain-mlogloss:1.67952\teval-mlogloss:1.84216\n",
      "[28]\ttrain-mlogloss:1.66314\teval-mlogloss:1.83006\n",
      "[29]\ttrain-mlogloss:1.64781\teval-mlogloss:1.81917\n",
      "[30]\ttrain-mlogloss:1.63304\teval-mlogloss:1.80883\n",
      "[31]\ttrain-mlogloss:1.61831\teval-mlogloss:1.79857\n",
      "[32]\ttrain-mlogloss:1.60421\teval-mlogloss:1.78870\n",
      "[33]\ttrain-mlogloss:1.59082\teval-mlogloss:1.77951\n",
      "[34]\ttrain-mlogloss:1.57783\teval-mlogloss:1.77080\n",
      "[35]\ttrain-mlogloss:1.56490\teval-mlogloss:1.76211\n",
      "[36]\ttrain-mlogloss:1.55288\teval-mlogloss:1.75426\n",
      "[37]\ttrain-mlogloss:1.54088\teval-mlogloss:1.74650\n",
      "[38]\ttrain-mlogloss:1.52943\teval-mlogloss:1.73930\n",
      "[39]\ttrain-mlogloss:1.51863\teval-mlogloss:1.73243\n",
      "[40]\ttrain-mlogloss:1.50786\teval-mlogloss:1.72564\n",
      "[41]\ttrain-mlogloss:1.49719\teval-mlogloss:1.71917\n",
      "[42]\ttrain-mlogloss:1.48681\teval-mlogloss:1.71270\n",
      "[43]\ttrain-mlogloss:1.47660\teval-mlogloss:1.70665\n",
      "[44]\ttrain-mlogloss:1.46699\teval-mlogloss:1.70113\n",
      "[45]\ttrain-mlogloss:1.45715\teval-mlogloss:1.69530\n",
      "[46]\ttrain-mlogloss:1.44774\teval-mlogloss:1.68996\n",
      "[47]\ttrain-mlogloss:1.43845\teval-mlogloss:1.68439\n",
      "[48]\ttrain-mlogloss:1.42939\teval-mlogloss:1.67933\n",
      "[49]\ttrain-mlogloss:1.42048\teval-mlogloss:1.67435\n",
      "[50]\ttrain-mlogloss:1.41182\teval-mlogloss:1.66964\n",
      "[51]\ttrain-mlogloss:1.40353\teval-mlogloss:1.66520\n",
      "[52]\ttrain-mlogloss:1.39535\teval-mlogloss:1.66088\n",
      "[53]\ttrain-mlogloss:1.38717\teval-mlogloss:1.65658\n",
      "[54]\ttrain-mlogloss:1.37917\teval-mlogloss:1.65248\n",
      "[55]\ttrain-mlogloss:1.37136\teval-mlogloss:1.64831\n",
      "[56]\ttrain-mlogloss:1.36378\teval-mlogloss:1.64454\n",
      "[57]\ttrain-mlogloss:1.35640\teval-mlogloss:1.64063\n",
      "[58]\ttrain-mlogloss:1.34899\teval-mlogloss:1.63693\n",
      "[59]\ttrain-mlogloss:1.34168\teval-mlogloss:1.63336\n",
      "[60]\ttrain-mlogloss:1.33433\teval-mlogloss:1.62962\n",
      "[61]\ttrain-mlogloss:1.32711\teval-mlogloss:1.62620\n",
      "[62]\ttrain-mlogloss:1.32024\teval-mlogloss:1.62281\n",
      "[63]\ttrain-mlogloss:1.31334\teval-mlogloss:1.61954\n",
      "[64]\ttrain-mlogloss:1.30650\teval-mlogloss:1.61640\n",
      "[65]\ttrain-mlogloss:1.29999\teval-mlogloss:1.61327\n",
      "[66]\ttrain-mlogloss:1.29354\teval-mlogloss:1.61027\n",
      "[67]\ttrain-mlogloss:1.28735\teval-mlogloss:1.60756\n",
      "[68]\ttrain-mlogloss:1.28108\teval-mlogloss:1.60475\n",
      "[69]\ttrain-mlogloss:1.27505\teval-mlogloss:1.60209\n",
      "[70]\ttrain-mlogloss:1.26880\teval-mlogloss:1.59932\n",
      "[71]\ttrain-mlogloss:1.26273\teval-mlogloss:1.59682\n",
      "[72]\ttrain-mlogloss:1.25654\teval-mlogloss:1.59420\n",
      "[73]\ttrain-mlogloss:1.25056\teval-mlogloss:1.59151\n",
      "[74]\ttrain-mlogloss:1.24476\teval-mlogloss:1.58915\n",
      "[75]\ttrain-mlogloss:1.23876\teval-mlogloss:1.58676\n",
      "[76]\ttrain-mlogloss:1.23305\teval-mlogloss:1.58452\n",
      "[77]\ttrain-mlogloss:1.22723\teval-mlogloss:1.58231\n",
      "[78]\ttrain-mlogloss:1.22143\teval-mlogloss:1.58010\n",
      "[79]\ttrain-mlogloss:1.21580\teval-mlogloss:1.57791\n",
      "[80]\ttrain-mlogloss:1.21023\teval-mlogloss:1.57579\n",
      "[81]\ttrain-mlogloss:1.20463\teval-mlogloss:1.57362\n",
      "[82]\ttrain-mlogloss:1.19925\teval-mlogloss:1.57162\n",
      "[83]\ttrain-mlogloss:1.19376\teval-mlogloss:1.56943\n",
      "[84]\ttrain-mlogloss:1.18844\teval-mlogloss:1.56745\n",
      "[85]\ttrain-mlogloss:1.18305\teval-mlogloss:1.56548\n",
      "[86]\ttrain-mlogloss:1.17757\teval-mlogloss:1.56358\n",
      "[87]\ttrain-mlogloss:1.17235\teval-mlogloss:1.56176\n",
      "[88]\ttrain-mlogloss:1.16715\teval-mlogloss:1.56002\n",
      "[89]\ttrain-mlogloss:1.16192\teval-mlogloss:1.55812\n",
      "[90]\ttrain-mlogloss:1.15664\teval-mlogloss:1.55636\n",
      "[91]\ttrain-mlogloss:1.15178\teval-mlogloss:1.55468\n",
      "[92]\ttrain-mlogloss:1.14673\teval-mlogloss:1.55291\n",
      "[93]\ttrain-mlogloss:1.14164\teval-mlogloss:1.55133\n",
      "[94]\ttrain-mlogloss:1.13659\teval-mlogloss:1.54958\n",
      "[95]\ttrain-mlogloss:1.13164\teval-mlogloss:1.54800\n",
      "[96]\ttrain-mlogloss:1.12671\teval-mlogloss:1.54629\n",
      "[97]\ttrain-mlogloss:1.12192\teval-mlogloss:1.54469\n",
      "[98]\ttrain-mlogloss:1.11712\teval-mlogloss:1.54311\n",
      "[99]\ttrain-mlogloss:1.11225\teval-mlogloss:1.54165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [23:01:25] WARNING: /workspace/src/common/error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [23:01:25] WARNING: /workspace/src/c_api/c_api.cc:1240: Saving into deprecated binary model format, please consider using `json` or `ubj`. Model format will default to JSON in XGBoost 2.2 if not specified.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "\n",
    "\n",
    "\n",
    "# Define the XGBoost parameters to utilize the GPU\n",
    "# Use 'gpu_hist' for the 'tree_method' to use GPU accelerated algorithms.\n",
    "params = {\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': len(set(y_train)),  # Specify the number of classes if it's a multi-class classification\n",
    "    'tree_method': 'gpu_hist',       # Use GPU acceleration\n",
    "    'eval_metric': 'mlogloss',       # Multiclass logloss for evaluation\n",
    "    'learning_rate': 0.1,            # Learning rate\n",
    "    'max_depth': 6,                  # Depth of the trees\n",
    "    'min_child_weight': 1,           # Minimum sum of instance weight (hessian) needed in a child\n",
    "    'subsample': 0.8,                # Subsample ratio of the training instances\n",
    "    'colsample_bytree': 0.8,         # Subsample ratio of columns when constructing each tree\n",
    "    'num_round': 100                 # Number of boosting rounds\n",
    "}\n",
    "\n",
    "# Define evaluation set\n",
    "eval_set = [(dtrain, 'train'), (xgb.DMatrix(X_val, label=y_val_encoded), 'eval')]\n",
    "\n",
    "# Train the model with evals to watch performance\n",
    "gpu_model = xgb.train(params, dtrain, num_boost_round=params['num_round'], evals=eval_set)\n",
    "\n",
    "# Save the model\n",
    "gpu_model.save_model('xgb_model_gpu.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83a2aaf3-cf85-4f0a-81ab-3dc4b352e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for both training and validation sets\n",
    "dtrain_eval = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "dval_eval = xgb.DMatrix(X_val, label=y_val_encoded)\n",
    "\n",
    "# Predict using the GPU model\n",
    "y_train_pred = gpu_model.predict(dtrain_eval)\n",
    "y_val_pred = gpu_model.predict(dval_eval)\n",
    "\n",
    "# Since the model's objective is 'multi:softmax', it outputs the predicted class directly\n",
    "# If using 'multi:softprob', you would use `np.argmax()` to get predictions from probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "506dec58-d0ed-46de-bedf-bd0b88662f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 67.54%\n",
      "Validation Accuracy: 53.85%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train_encoded, y_train_pred)\n",
    "val_accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0e4ce07-8ad9-4028-96fb-fcb560801a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.38      0.50      3701\n",
      "           1       1.00      1.00      1.00       722\n",
      "           2       0.93      0.98      0.95      1033\n",
      "           3       0.63      0.41      0.49      5877\n",
      "           4       0.73      0.34      0.46      5857\n",
      "           5       0.53      0.49      0.51      5850\n",
      "           6       0.66      0.47      0.55      5743\n",
      "           7       0.76      0.61      0.68      5586\n",
      "           8       0.98      0.32      0.49      2057\n",
      "           9       0.73      0.70      0.71     12974\n",
      "          10       0.92      0.19      0.32      2269\n",
      "          11       0.83      0.65      0.73      4031\n",
      "          12       0.64      0.98      0.77    102576\n",
      "          13       0.89      0.32      0.47      2710\n",
      "          14       0.90      0.26      0.41      3108\n",
      "          15       0.87      0.27      0.41      3130\n",
      "          16       0.91      0.38      0.54      2222\n",
      "          17       0.98      0.99      0.99       657\n",
      "          18       0.94      0.97      0.95      1755\n",
      "          19       0.61      0.20      0.31      9009\n",
      "          20       0.82      0.19      0.31      4243\n",
      "          21       0.87      0.47      0.61      4147\n",
      "          22       0.97      0.16      0.27      4396\n",
      "          23       0.59      0.33      0.43      9265\n",
      "          24       0.88      0.45      0.59      3482\n",
      "          25       0.97      0.08      0.15      4218\n",
      "          26       0.99      0.99      0.99       862\n",
      "          27       0.68      0.45      0.54      5571\n",
      "          28       0.72      0.44      0.54      5900\n",
      "          29       0.91      0.96      0.94       657\n",
      "          30       0.70      0.57      0.63     12511\n",
      "          31       0.73      0.59      0.65     13875\n",
      "          32       0.96      0.97      0.96      3261\n",
      "\n",
      "    accuracy                           0.68    253255\n",
      "   macro avg       0.82      0.53      0.60    253255\n",
      "weighted avg       0.71      0.68      0.64    253255\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.14      0.21       925\n",
      "           1       1.00      0.89      0.94       180\n",
      "           2       0.83      0.78      0.80       258\n",
      "           3       0.11      0.06      0.08      1469\n",
      "           4       0.11      0.04      0.06      1464\n",
      "           5       0.15      0.15      0.15      1463\n",
      "           6       0.36      0.25      0.30      1436\n",
      "           7       0.50      0.36      0.42      1396\n",
      "           8       0.35      0.03      0.05       514\n",
      "           9       0.56      0.55      0.55      3244\n",
      "          10       0.11      0.01      0.01       567\n",
      "          11       0.53      0.34      0.41      1008\n",
      "          12       0.59      0.97      0.74     25644\n",
      "          13       0.15      0.03      0.06       677\n",
      "          14       0.22      0.03      0.06       777\n",
      "          15       0.16      0.04      0.06       783\n",
      "          16       0.19      0.03      0.05       556\n",
      "          17       0.83      0.66      0.74       164\n",
      "          18       0.78      0.78      0.78       439\n",
      "          19       0.23      0.07      0.10      2253\n",
      "          20       0.38      0.05      0.09      1061\n",
      "          21       0.39      0.13      0.19      1037\n",
      "          22       0.07      0.00      0.01      1099\n",
      "          23       0.26      0.15      0.19      2316\n",
      "          24       0.53      0.15      0.24       870\n",
      "          25       0.11      0.00      0.00      1054\n",
      "          26       0.93      0.69      0.79       216\n",
      "          27       0.18      0.11      0.13      1393\n",
      "          28       0.29      0.16      0.20      1475\n",
      "          29       0.60      0.46      0.52       164\n",
      "          30       0.48      0.39      0.43      3128\n",
      "          31       0.53      0.42      0.47      3469\n",
      "          32       0.87      0.83      0.85       815\n",
      "\n",
      "    accuracy                           0.54     63314\n",
      "   macro avg       0.42      0.30      0.32     63314\n",
      "weighted avg       0.46      0.54      0.46     63314\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print classification report for both training and validation\n",
    "print(\"Training Classification Report:\")\n",
    "print(classification_report(y_train_encoded, y_train_pred))\n",
    "\n",
    "print(\"Validation Classification Report:\")\n",
    "print(classification_report(y_val_encoded, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b950fb-faed-4912-988c-ab3ee2057466",
   "metadata": {},
   "source": [
    "## LSTM Model on BERT Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68cde4f9-ec2f-4a15-9ed3-a14eb3b9548a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Setting up the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b08d471-a652-4079-9abf-d147ac3d26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Assuming X_train includes embeddings concatenated with two additional features\n",
    "# and is already appropriately scaled/normalized\n",
    "\n",
    "# Convert data to PyTorch tensors and move to the appropriate device\n",
    "train_data = TensorDataset(\n",
    "    torch.tensor(X_train).float().to(device),  # ensure X_train is properly formatted and normalized\n",
    "    torch.tensor(y_train_encoded).long().to(device)\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Similar for validation data\n",
    "val_data = TensorDataset(\n",
    "    torch.tensor(X_val).float().to(device), \n",
    "    torch.tensor(y_val_encoded).long().to(device)\n",
    ")\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7f306e7-b6c9-44e2-9461-a4ab513c5043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassifier(\n",
       "  (lstm): LSTM(768, 256, batch_first=True, bidirectional=True)\n",
       "  (attention): Attention(\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (fc1): Linear(in_features=514, out_features=512, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (fc2): Linear(in_features=512, out_features=33, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30629edd-a208-40d5-9e3a-9bb2cbc9f9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for embeddings, labels in val_loader:\n",
    "            outputs = model(embeddings)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7024f7d-9630-4625-8787-5c52e818ee07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([32, 770])\n",
      "Embeddings shape: torch.Size([32, 768])\n",
      "Additional features shape: torch.Size([32, 2])\n",
      "LSTM output shape: torch.Size([32, 512])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m embeddings, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, embeddings\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 41\u001b[0m, in \u001b[0;36mTextClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lstm_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Attention processing\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m attention_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlstm_out\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttention output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, attention_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Concatenate the output of the attention layer with the additional features\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m, in \u001b[0;36mAttention.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# Assume hidden_states shape: [batch_size, seq_len, num_directions * hidden_size]\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(attention_scores)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     13\u001b[0m     attended \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m*\u001b[39m hidden_states\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "for embeddings, labels in train_loader:\n",
    "    print(\"Embeddings shape:\", embeddings.shape)\n",
    "    outputs = model(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2230a1c6-68fa-490c-8ff9-db1c71b0a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                    | 0/100 [00:00<?, ?it/s]/home/sadibha2/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /opt/conda/conda-bld/pytorch_1704987296916/work/aten/src/ATen/native/cudnn/RNN.cpp:982.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "  0%|                                                                                                                    | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[788480, 1]' is invalid for input of size 786432",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (embeddings, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     14\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     17\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mTextClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 25\u001b[0m     lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     attention_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(lstm_out)\n\u001b[1;32m     27\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(attention_out)\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/localization/lib/python3.12/site-packages/torch/nn/modules/rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[788480, 1]' is invalid for input of size 786432"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training and validation loop\n",
    "num_epochs = 100\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()  # Ensure the model is in training mode\n",
    "    running_loss = 0.0\n",
    "    for i, (embeddings, labels) in enumerate(train_loader, 1):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embeddings)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:  # Print every 100 mini-batches\n",
    "            print(f'Epoch {epoch + 1}, Batch {i}, Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # Validation accuracy\n",
    "    val_accuracy = evaluate(model, val_loader)\n",
    "    print(f'Validation Accuracy after Epoch {epoch + 1}: {val_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c26ef15-ae68-468b-a8e3-280f216dae98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Assuming the dataset and labels are loaded correctly and y_train_encoded is available\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m X_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mX_train\u001b[49m)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# Ensure X_train is a numpy array or similar\u001b[39;00m\n\u001b[1;32m     12\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y_train_encoded)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# If using a GPU, move data to GPU\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import torch._dynamo\n",
    "torch._dynamo.disable()\n",
    "\n",
    "\n",
    "# Assuming the dataset and labels are loaded correctly and y_train_encoded is available\n",
    "X_train_tensor = torch.tensor(X_train).float()  # Ensure X_train is a numpy array or similar\n",
    "y_train_tensor = torch.tensor(y_train_encoded).long()\n",
    "\n",
    "# If using a GPU, move data to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor, y_train_tensor = X_train_tensor.to(device), y_train_tensor.to(device)\n",
    "\n",
    "# DataLoader setup\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "model = TextClassifier(embedding_dim=768, hidden_dim=256, num_classes=len(set(y_train_encoded)))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in tqdm(range(100)):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89263ff6-0592-4b31-995d-42f7ad559b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
